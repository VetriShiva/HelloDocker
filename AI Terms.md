```
Perfect. Below are INTERVIEW FLASH CARDS â€” short, crisp, question â†’ answer format.
You can memorize, print, or convert this into Anki/Notion easily.
ğŸ§  AI INTERVIEW FLASH CARDS (Architect Level)
ğŸŸ¦ Card 1: What is Artificial Intelligence (AI)?
Answer:
AI is the broad field of making machines perform tasks that normally require human intelligence, such as reasoning, decision-making, and problem-solving.
ğŸŸ¦ Card 2: What problem does AI solve?
Answer:
It automates intelligent decision-making where human intervention is expensive, slow, or inconsistent.
ğŸŸ¦ Card 3: What is Machine Learning (ML)?
Answer:
ML is a subset of AI where systems learn patterns from historical data instead of being explicitly programmed with rules.
ğŸŸ¦ Card 4: When do you choose ML over rule-based AI?
Answer:
When rules are hard to define, data is available, and predictions are needed at scale.
ğŸŸ¦ Card 5: What is Deep Learning (DL)?
Answer:
Deep Learning is a subset of ML that uses multi-layer neural networks to learn complex patterns from large volumes of data.
ğŸŸ¦ Card 6: Why is Deep Learning powerful?
Answer:
Because it automatically learns features from raw data and scales well with large datasets.
ğŸŸ¦ Card 7: What is a Neural Network?
Answer:
A neural network is a layered mathematical model that learns by adjusting weights to approximate complex functions.
ğŸŸ¦ Card 8: What is Natural Language Processing (NLP)?
Answer:
NLP is the domain of AI focused on enabling machines to understand, analyze, and work with human language.
ğŸŸ¦ Card 9: Is NLP a model or a domain?
Answer:
NLP is a domain; it can be implemented using rules, ML, or Deep Learning.
ğŸŸ¦ Card 10: What is Generative AI?
Answer:
Generative AI refers to models that create new content such as text, images, code, or audio instead of just classifying data.
ğŸŸ¦ Card 11: How is Generative AI different from ML?
Answer:
Traditional ML predicts labels or values, while Generative AI produces new, original content.
ğŸŸ¦ Card 12: What is a Large Language Model (LLM)?
Answer:
An LLM is a deep learning model trained on massive text data to predict the next token, enabling natural language understanding and generation.
ğŸŸ¦ Card 13: Why are LLMs called â€œlargeâ€?
Answer:
Because they are trained with billions to trillions of parameters and massive datasets.
ğŸŸ¦ Card 14: What is a Token in LLMs?
Answer:
A token is the smallest unit of text processed by an LLM, such as a word, sub-word, or character.
ğŸŸ¦ Card 15: Why are tokens important?
Answer:
They directly affect cost, latency, and the modelâ€™s context window.
ğŸŸ¦ Card 16: What is a Context Window?
Answer:
The maximum number of tokens an LLM can process in a single request, including prompt and history.
ğŸŸ¦ Card 17: What are Parameters in a model?
Answer:
Parameters are trainable weights that store the knowledge learned during training.
ğŸŸ¦ Card 18: Does more parameters always mean better?
Answer:
No. More parameters increase capacity but not necessarily accuracy or efficiency.
ğŸŸ¦ Card 19: What is Pre-training?
Answer:
Pre-training is training a model on massive general-purpose data to learn language and world knowledge.
ğŸŸ¦ Card 20: What is Fine-tuning?
Answer:
Fine-tuning is additional training on task-specific or domain-specific data to specialize a model.
ğŸŸ¦ Card 21: What are Embeddings?
Answer:
Embeddings are numerical vector representations of text that capture semantic meaning.
ğŸŸ¦ Card 22: Where are embeddings used?
Answer:
Search, clustering, recommendation systems, and RAG pipelines.
ğŸŸ¦ Card 23: What is a Vector Database?
Answer:
A database optimized for storing embeddings and performing fast similarity searches.
ğŸŸ¦ Card 24: What is RAG (Retrieval-Augmented Generation)?
Answer:
RAG combines LLMs with external data retrieval to produce accurate, up-to-date, and grounded responses.
ğŸŸ¦ Card 25: Why is RAG important?
Answer:
It reduces hallucinations and removes the need to retrain models for new data.
ğŸŸ¦ Card 26: What is Hallucination in LLMs?
Answer:
Hallucination occurs when an LLM generates confident but incorrect or fabricated information.
ğŸŸ¦ Card 27: How do you reduce hallucinations?
Answer:
Using RAG, strict prompting, validation, and guardrails.
ğŸŸ¦ Card 28: What is a Prompt?
Answer:
A prompt is the instruction and context provided to an LLM to guide its output.
ğŸŸ¦ Card 29: Why is prompting important?
Answer:
Because LLM behavior is highly sensitive to how instructions and context are framed.
ğŸŸ¦ Card 30: What is Temperature in LLMs?
Answer:
A parameter that controls randomness; low values are deterministic, high values are creative.
ğŸŸ¦ Card 31: What is Inference?
Answer:
Inference is running a trained model to generate predictions or responses.
ğŸŸ¦ Card 32: What are Guardrails?
Answer:
Guardrails are controls that ensure safety, compliance, and correctness of AI outputs.
ğŸŸ¦ Card 33: Explain the AI hierarchy.
Answer:
AI â†’ Machine Learning â†’ Deep Learning â†’ Generative AI â†’ LLM.
ğŸŸ¦ Card 34: Where does NLP fit in the hierarchy?
Answer:
NLP is a language-focused domain used by AI, ML, DL, and especially LLMs.
ğŸŸ¦ Card 35: When should an architect choose LLM + RAG?
Answer:
For chatbots, document Q&A, copilots, and enterprise knowledge assistants.
ğŸ¯ FINAL MEMORY CARD (Most Important)
Q: One sentence to explain everything?
A:
AI is the goal, ML learns from data, DL learns complex patterns, NLP handles language, Generative AI creates content, and LLMs generate language at scale.
If you want next:
ğŸ“„ Printable PDF flash cards
ğŸ§  Anki-ready CSV
ğŸ¦ Banking-domain interview flash cards
ğŸ— Architecture whiteboard answers
Just say the word ğŸ‘
```